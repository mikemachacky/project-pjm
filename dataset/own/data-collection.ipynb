{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "60264dac428d3de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:42:43.493890Z",
     "start_time": "2025-06-05T14:42:42.690348Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -q mediapipe",
   "id": "1efd457b7e4d6f15",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Skrypt",
   "id": "f8895403bc72452e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T07:50:22.587378Z",
     "start_time": "2025-08-20T07:46:17.566941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Inicjalizacja MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# Dane wejściowe\n",
    "user_id = input(\"Podaj ID użytkownika: \").strip()\n",
    "label = input(\"Podaj literę języka migowego (np. A): \").upper().strip()\n",
    "num_samples = int(input(\"Podaj liczbę próbek do nagrania: \"))\n",
    "\n",
    "# Baza danych\n",
    "db_path = '../../PJM-sign-language.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Nazwa tabeli na podstawie litery\n",
    "table_name = f\"{label}\"\n",
    "\n",
    "# Tworzenie tabeli jeśli nie istnieje\n",
    "cursor.execute(f'''\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    user_id TEXT,\n",
    "    label TEXT,\n",
    "    sample_id INTEGER,\n",
    "    frame INTEGER,\n",
    "    ''' + ', '.join([f'landmark_{i}_{axis} REAL' for i in range(1, 22) for axis in ('x', 'y', 'z')]) + ''')\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "# Kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "sample_counter = 0\n",
    "FRAME_RATE = 15\n",
    "DURATION_SEC = 2\n",
    "TOTAL_FRAMES = FRAME_RATE * DURATION_SEC\n",
    "\n",
    "print(f\"\\nNaciśnij SPACJĘ aby nagrać próbkę (15 FPS, 2 sekundy) dla litery '{label}'. 'q' aby zakończyć.\")\n",
    "\n",
    "while sample_counter < num_samples:\n",
    "    # Pobierz ostatni sample_id\n",
    "    cursor.execute(f\"SELECT MAX(sample_id) FROM {table_name} WHERE user_id = ? AND label = ?\", (user_id, label))\n",
    "    result = cursor.fetchone()\n",
    "    next_sample_id = (result[0] + 1) if result[0] is not None else 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Nie można odczytać klatki z kamery.\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        display_text = f\"User: {user_id}  Label: {label}  Sample: {sample_counter+1}/{num_samples}\"\n",
    "        cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"Nacisnij SPACJE aby nagrywac\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Kamera\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):  # Spacja - rozpoczęcie nagrania\n",
    "            print(\"Rozpoczynanie nagrywania...\")\n",
    "            frame_count = 0\n",
    "\n",
    "            while frame_count < TOTAL_FRAMES:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Błąd odczytu z kamery.\")\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(rgb_frame)\n",
    "\n",
    "                draw_frame = frame.copy()\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(draw_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    landmarks = results.multi_hand_landmarks[0].landmark\n",
    "                    row = [user_id, label, next_sample_id, frame_count]\n",
    "                    for lm in landmarks[:21]:\n",
    "                        row += [lm.x, lm.y, lm.z]\n",
    "                    placeholders = ','.join(['?'] * len(row))\n",
    "                    cursor.execute(f\"INSERT INTO {table_name} VALUES ({placeholders})\", row)\n",
    "                    conn.commit()\n",
    "\n",
    "                    frame_count += 1  # Zliczaj tylko gdy jest dłoń\n",
    "\n",
    "                cv2.putText(draw_frame, f\"NAGRYWANIE {frame_count}/{TOTAL_FRAMES}\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.imshow(\"Kamera\", draw_frame)\n",
    "                cv2.waitKey(1)\n",
    "                time.sleep(1 / FRAME_RATE)\n",
    "\n",
    "            print(f\"Zakończono nagrywanie próbki {next_sample_id}.\")\n",
    "            sample_counter += 1\n",
    "            break\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            conn.close()\n",
    "            print(\"Zakończono.\")\n",
    "            exit()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.close()\n",
    "print(f\"Zakończono nagrywanie. Dane zapisane do '{db_path}'.\")\n"
   ],
   "id": "d6826d47df0a2d2f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 09:46:18.313983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755675978.328839   26644 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755675978.333395   26644 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755675978.345344   26644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755675978.345361   26644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755675978.345363   26644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755675978.345364   26644 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-20 09:46:18.349401: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1755675980.549366   27613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755675980.571943   27613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naciśnij SPACJĘ aby nagrać próbkę (15 FPS, 2 sekundy) dla litery 'A'. 'q' aby zakończyć.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "W0000 00:00:1755675989.736441   27616 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zakończono.\n",
      "Nie można odczytać klatki z kamery.\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mProgrammingError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mNaciśnij SPACJĘ aby nagrać próbkę (15 FPS, 2 sekundy) dla litery \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m. \u001B[39m\u001B[33m'\u001B[39m\u001B[33mq\u001B[39m\u001B[33m'\u001B[39m\u001B[33m aby zakończyć.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m sample_counter < num_samples:\n\u001B[32m     46\u001B[39m     \u001B[38;5;66;03m# Pobierz ostatni sample_id\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m     \u001B[43mcursor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mSELECT MAX(sample_id) FROM \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtable_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m WHERE user_id = ? AND label = ?\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m     result = cursor.fetchone()\n\u001B[32m     49\u001B[39m     next_sample_id = (result[\u001B[32m0\u001B[39m] + \u001B[32m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m result[\u001B[32m0\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m0\u001B[39m\n",
      "\u001B[31mProgrammingError\u001B[39m: Cannot operate on a closed database."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1 - Magdalena Machacka\n",
    "2 - Piotr Kurdziel\n",
    "3 - Błażej Krasucki"
   ],
   "id": "7e06e1ef3006a542"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
