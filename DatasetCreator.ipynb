{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset",
   "id": "60264dac428d3de9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:46:36.337191Z",
     "start_time": "2025-05-13T13:46:34.679810Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -q mediapipe",
   "id": "1efd457b7e4d6f15",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Skrypt",
   "id": "f8895403bc72452e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:51:33.015265Z",
     "start_time": "2025-05-13T13:51:07.078854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import sqlite3\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Inicjalizacja MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# Dane wejściowe\n",
    "user_id = input(\"Podaj ID użytkownika: \").strip()\n",
    "label = input(\"Podaj literę języka migowego (np. A): \").upper().strip()\n",
    "num_samples = int(input(\"Podaj liczbę próbek do nagrania: \"))\n",
    "\n",
    "# Baza danych\n",
    "db_path = 'PJM-sign-language.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Nazwa tabeli na podstawie litery\n",
    "table_name = f\"{label}\"\n",
    "\n",
    "# Tworzenie tabeli jeśli nie istnieje\n",
    "cursor.execute(f'''\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    user_id TEXT,\n",
    "    label TEXT,\n",
    "    sample_id INTEGER,\n",
    "    frame INTEGER,\n",
    "    ''' + ', '.join([f'landmark_{i}_{axis} REAL' for i in range(1, 22) for axis in ('x', 'y', 'z')]) + ''')\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "# Kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "sample_counter = 0\n",
    "FRAME_RATE = 15\n",
    "DURATION_SEC = 2\n",
    "TOTAL_FRAMES = FRAME_RATE * DURATION_SEC\n",
    "\n",
    "print(f\"\\nNaciśnij SPACJĘ aby nagrać próbkę (15 FPS, 2 sekundy) dla litery '{label}'. 'q' aby zakończyć.\")\n",
    "\n",
    "while sample_counter < num_samples:\n",
    "    # Pobierz ostatni sample_id\n",
    "    cursor.execute(f\"SELECT MAX(sample_id) FROM {table_name} WHERE user_id = ? AND label = ?\", (user_id, label))\n",
    "    result = cursor.fetchone()\n",
    "    next_sample_id = (result[0] + 1) if result[0] is not None else 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Nie można odczytać klatki z kamery.\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        display_text = f\"User: {user_id}  Label: {label}  Sample: {sample_counter+1}/{num_samples}\"\n",
    "        cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, \"Nacisnij SPACJE aby nagrywac\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Kamera\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):  # Spacja - rozpoczęcie nagrania\n",
    "            print(\"Rozpoczynanie nagrywania...\")\n",
    "            frame_count = 0\n",
    "\n",
    "            while frame_count < TOTAL_FRAMES:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Błąd odczytu z kamery.\")\n",
    "                    break\n",
    "\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(rgb_frame)\n",
    "\n",
    "                draw_frame = frame.copy()\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        mp_drawing.draw_landmarks(draw_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    landmarks = results.multi_hand_landmarks[0].landmark\n",
    "                    row = [user_id, label, next_sample_id, frame_count]\n",
    "                    for lm in landmarks[:21]:\n",
    "                        row += [lm.x, lm.y, lm.z]\n",
    "                    placeholders = ','.join(['?'] * len(row))\n",
    "                    cursor.execute(f\"INSERT INTO {table_name} VALUES ({placeholders})\", row)\n",
    "                    conn.commit()\n",
    "\n",
    "                    frame_count += 1  # Zliczaj tylko gdy jest dłoń\n",
    "\n",
    "                cv2.putText(draw_frame, f\"NAGRYWANIE {frame_count}/{TOTAL_FRAMES}\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.imshow(\"Kamera\", draw_frame)\n",
    "                cv2.waitKey(1)\n",
    "                time.sleep(1 / FRAME_RATE)\n",
    "\n",
    "            print(f\"Zakończono nagrywanie próbki {next_sample_id}.\")\n",
    "            sample_counter += 1\n",
    "            break\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            conn.close()\n",
    "            print(\"Zakończono.\")\n",
    "            exit()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.close()\n",
    "print(f\"Zakończono nagrywanie. Dane zapisane do '{db_path}'.\")\n"
   ],
   "id": "d6826d47df0a2d2f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747144267.130169   67622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747144267.158135   67622 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naciśnij SPACJĘ aby nagrać próbkę (15 FPS, 2 sekundy) dla litery 'Z_X'. 'q' aby zakończyć.\n",
      "Rozpoczynanie nagrywania...\n",
      "Zakończono nagrywanie próbki 0.\n",
      "Rozpoczynanie nagrywania...\n",
      "Zakończono nagrywanie próbki 1.\n",
      "Zakończono nagrywanie. Dane zapisane do 'PJM-sign-language.db'.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
